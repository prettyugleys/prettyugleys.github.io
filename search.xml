<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[The Economist(2014.11.24) Should digital monopolies be broken up?]]></title>
    <url>%2F2018%2F04%2F26%2FTE05%2F</url>
    <content type="text"><![CDATA[###European moves against Google are about protecting companies, not consumers 欧洲反抗Google的运动意在保护其企业，而非消费者 ALTHOUGH no company is mentioned by name, it is very clear which American internet giant the European Parliament has in mind in a resolution that has been doing the rounds in the run-up to a vote on November 27th. One draft calls for “unbundling search engines from other commercial services” to ensure a level playing field for European companies and consumers. This is the latest and most dramatic outbreak of Googlephobia in Europe. 虽然没有任何公司的名字被提及，但很显然的是欧洲委员会已经将哪些美国科技巨头放入11.27号前夕的投票决议中。一项草案呼吁解除搜索引擎与其他商业服务的绑定，以确保对欧洲企业和消费者有一个相对公平的环境。这是最新的，最具戏剧性的欧洲谷歌恐惧症的爆发。 Europe’s former competition commissioner, Joaquín Almunia, brokered a series of settlements this year requiring Google to give more prominence to rivals’ shopping and map services alongside its own in search results. But MEPs want his successor, Margrethe Vestager, to take a firmer line. Hence the calls to dismember the company. 欧洲前竞争委员会委员，Joaqurn Almunia在今年调和了一系列协议，协议要求google给竞争对手的购物和地图方面提供更多的内容，并将其纳入他自己的搜索结果中。不过欧洲议会会员们希望他们的继任Magrethe Vestager 采取更强硬的措施。强烈呼吁解散公司。 The parliament does not actually have the power to carry out this threat. But it touches on a question that has been raised by politicians from Washington to Seoul and brings together all sorts of issues from privacy to industrial policy (see article). How worrying is the dominance of the internet by Google and a handful of other firms? 议会倒是没有什么实际的能力来实施这一威胁，但是他触及了一个已经被从华盛顿到首尔的政客们所提出的问题。被G和其他公司主导的互联网究竟是有多令人担忧？ Who’s afraid of the big bad search engine? Google (whose executive chairman, Eric Schmidt, is a member of the board of The Economist’s parent company) has 68% of the market of web searches in America and more than 90% in many European countries. Like Facebook, Amazon and other tech giants, it benefits from the network effects whereby the popularity of a service attracts more users and thus becomes self-perpetuating. It collects more data than any other company and is better at mining those data for insights. Once people start using Google’s search (and its e-mail, maps and digital storage), they rarely move on. Small advertisers find switching to another platform too burdensome to bother. Google（其执行董事长Eric Schmidit，是经济学人母公司的董事） 在美国有%68的web搜索市场，还有%90的市场在许多欧洲国家。像FB,Amazon和其他的科技巨头一样，通过普及一个业务来吸引更多的用户并因此自我延续。G收集了比其他公司更多的数据，且更擅长挖掘这些数据及洞察力。一旦人们开始使用Google搜索（还有他的邮件，地图和数字存储服务），他们基本不用做什么。小广告商寻找另一个平台则需要做额外的工作以至于他们承受不了。 Google is clearly dominant, then; but whether it abuses that dominance is another matter. It stands accused of favouring its own services in search results, making it hard for advertisers to manage campaigns across several online platforms, and presenting answers on some search pages directly rather than referring users to other websites. But its behaviour is not in the same class as Microsoft’s systematic campaign against the Netscape browser in the late 1990s: there are no e-mails talking about “cutting off” competitors’ “air supply”. What’s more, some of the features that hurt Google’s competitors benefit its consumers. Giving people flight details, dictionary definitions or a map right away saves them time. And while advertisers often pay hefty rates for clicks, users get Google’s service for nothing—rather as plumbers and florists fork out to be listed in Yellow Pages which are given to readers gratis, and nightclubs charge men steep entry prices but let women in free. G显然占据主导地位，但是否其在滥用这个主导地位就是另一回事了。它被指控在搜索结果中偏袒自己的服务。使得广告商在一系列在线平台上的管控活动变得困难。并直接在搜索页面上提前发送搜索结果而不是引导用户去其他网站。但它这个行为并不与90年代后期的微软自动化活动抵制Netscape浏览器那样：没有电子邮件谈切断竞争对手的气源。更多的是一些特点伤害到了G的竞争对手从消费者那里获取利益。给人们提供航班信息，字典释义或地图以快速节约人的时间。虽然广告商支付很高的点击利息，这对消费者什么好处都没有——而不像水管工和花农花钱呗列在黄页上免费提供给读者，还有夜总会要求男士付门票而女士则不必 There are also good reasons why governments should regulate internet monopolies less energetically than offline ones. First, barriers to entry are lower in the digital realm. It has never been easier to launch a new online product or service: consider the rapid rise of Instagram, WhatsApp or Slack. Building a rival infrastructure to a physical incumbent is far more expensive (just ask telecoms operators or energy firms), and as a result there is much less competition (and more need for regulation) in the real world. True, big firms can always buy upstart rivals (as Facebook did with Instagram and WhatsApp, and Google did with Waze, Apture and many more). But such acquisitions then encourage the formation of even more start-ups, creating even more competition for incumbents. 有很多理由解释为什么政府应该花更少了精力规范互联网垄断而非线下。首先，进入数字领域的门槛低。从来没有这么容易推出一个在线的产品或服务：想想看快速兴起的Instagram,WahtsApp或Slack。建设一个可与之匹敌的基础设施到其成型则更加昂贵（只管去问电信运营商或能源公司）。并且它们在现实世界中有更少的竞争者（并需要更多的管控）。讲真，大公司经常能收购新兴竞争对手（就像FB对Ins和WhatsApp所做的那样），但是这种收购反而鼓励了更多出创公司的形成，对现有企业造成更多的竞争。 Second, although switching from Google and other online giants is not costless, their products do not lock customers in as Windows, Microsoft’s operating system, did. And although network effects may persist for a while, they do not confer a lasting advantage: consider the decline of MySpace, or more recently of Orkut, Google’s once-dominant social network in Brazil, both eclipsed by Facebook—itself threatened by a wave of messaging apps. 其次，从google和其他公司里选择的代价比较少，他们的产品并未像Windows那样锁住消费者。尽管其网络影响会持续存在一段时间，但它并没有赋予持久的优势：.…略… Finally, the lesson of recent decades is that technology monopolists (think of IBM in mainframes or Microsoft in PC operating systems) may be dominant for a while, but they are eventually toppled when they fail to move with the times, or when new technologies expand the market in unexpected ways, exposing them to new rivals. Facebook is eating into Google’s advertising revenue. Despite the success of Android, Google’s mobile platform, the rise of smartphones may undermine Google: users now spend more time on apps than on the web, and Google is gradually losing control of Android as other firms build their own mobile ecosystems on top of its open-source underpinnings. So far, no company has remained information technology’s top dog from one cycle to the next. Sometimes former monopolies end up with a lucrative franchise in a legacy area, as Microsoft and IBM have. But the kingdoms they rule turn out to be only part of a much larger map. 最后，近十年的经验教训是技术垄断可能会主导一段时间，但是他们最终会暴露给自己的对手当他们未与时俱进，或是当新技术以意想不到的方式扩大自己的市场 ###Looking after their own 管好你自己 The European Parliament’s Googlephobia looks a mask for two concerns, one worthier than the other. The lamentable one, which American politicians pointed out this week, is a desire to protect European companies. Among the loudest voices lobbying against Google are Axel Springer and Hubert Burda Media, two German media giants. Instead of attacking successful American companies, Europe’s leaders should ask themselves why their continent has not produced a Google or a Facebook. Opening up the EU’s digital services market would do more to create one than protecting local incumbents. 欧洲的谷歌恐惧症就就像一个面具，一面比另一面更有价值。然而美国政客们在本周指出，可悲的一面是其欲保护欧洲企业，在反对G的游说团体中发声最大的是阿克塞尔-施普林格（施普林格出版集团老板）和Hubert Burda（德国媒体巨头）这两个媒体巨头。欧洲领导人应该反思自己为什么他们的大州没有产出像Google和FB一样公司，而不是攻击美国的成功的企业。开放欧洲的数字市场将有主于创造这样（G/FB/Ama）的公司而非保护当地老牌企业。 The good reason for worrying about the internet giants is privacy. It is right to limit the ability of Google and Facebook to use personal data: their services should, for instance, come with default settings guarding privacy, so companies gathering personal information have to ask consumers to opt in. Europe’s politicians have shown more interest in this than American ones. But to address these concerns, they should regulate companies’ behaviour, not their market power. Some clearer thinking by European politicians would benefit the continent’s citizens. 担忧互联网巨头的一个重要原因是隐私。限制G和FB使用私人数据的权限是无可厚非的：如，他们的服务应该默认带有隐私保护，所以公司在使用私人数据时应告知客户寻得许可。欧洲的政客们在这方面表现出比美政客们更多的兴趣，但要表示这些担忧，他们应该规范公司的行为，而不是宏观调控市场。欧洲政客们三思而后行将会有益于欧洲的人民。​]]></content>
      <categories>
        <category>The Economist(经济学人)</category>
      </categories>
      <tags>
        <tag>Translate Magazines</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Attack of the cybermen]]></title>
    <url>%2F2018%2F04%2F26%2FTE04%2F</url>
    <content type="text"><![CDATA[####Sophisticated viruses will be the workhorses of 21st-century spying. But there should be rules 复杂病毒将成为21世纪情报工作的利器,但他们应该被规范。 IF ASKED why they spied on the computers of their rivals (and allies), the authors of Regin, a sophisticated computer virus that seems to have been designed by a Western government, would presumably echo the proverbial bank robber, and reply “because that’s where the secrets are”. 如果问为什么他们为什么暗中监视对手（和外国）的电脑，这个复杂的病毒看起来是被西方政府所设计的，也就是病毒(Regin)的始作甬者可能会像银行劫匪那样给出普遍的回答：“因为秘密就在哪里” As the world has gone digital, spying has, too. Regin is just the latest in a trend that first came to public notice in 2010, when a piece of American and Israeli software called Stuxnet was revealed to have been responsible for sabotaging part of Iran’s nuclear programme. Since then have come Flame, Red October, DarkHotel and others (see article); more surely lurk undiscovered in the world’s networks. But unlike the indiscriminate surveillance revealed by Edward Snowden, these chunks of malware seem, like traditional spying, to be targeted at specific governments or even individuals. 世界已经数字化，谍报工作也是。Regin也趋向此，只不过它是在2010年最早进入公众视野的一个，一个美国和以色列的叫做Stuxnet的软件被揭露，其要为破坏伊朗的部分核计划负责。 （Stuxnet，即震网，这货直接破坏了伊朗的核计划，伊朗都没察觉到这个病毒的存在） 这之后又出现了Falme，Red October，DarkHotel和其他病毒。显然还有其他未被发现的病毒于网络中。但和斯诺登所披露的不计后果的（软件）不同，这些不成规模的恶意软件就像传统间谍活动一样以特定的政府或和人为目标。 For spies, such digital espionage has advantages over the shoe-leather sort. Computers are stuffed with data that can be copied and beamed around the world in seconds—so much easier than fiddling with microdots or smuggling sensitive documents past guards. The more complicated computer operating systems get, the more riddled they are with unnoticed security holes. Staying safe means plugging them all; an attacker need only keep trying until a single one gives way. 对间谍们来说，这种数字间谍活动显然比那种藏在动物皮制成的鞋子里要好。计算机里充斥的数据能被复制，并在几分钟内被传播到世界各地很远的地方——这可比藏在胶卷里或偷渡敏感文件过安检要容易得多。越是复杂的操作系统，其不易被发现的安全漏洞就越多。保证安全就得把他们都补上。一个攻击者只要不断地试探直到找到一个就可以。 Computer espionage is usefully deniable, too: if programmers are careful it is hard to know who is behind an attack. (There are hints that Regin might be British—not least that one of its modules seems to be called “LEGSPIN”, a cricketing term. British spooks refuse to comment.) And it can be conducted from comfortable armchairs thousands of miles from the target, with no need to put human agents in harm’s way. 网络间谍活动也很容易被否认。如果程序员足够小心那么就很难发现背后的攻击者(有迹象表明Regin出自英国，它的模块中有一个好像叫做“LEGSPIN”的板球术语，英国间谍们对此不予置评）。这种活动可以从距目标千里之外的沙发上开展，而不用把特工置于险境。 But cyber-spying raises two tricky issues. One is that the low cost of gathering information this way may encourage more of it, and a Hobbesian world of spiralling espionage would be bad for everybody. What’s more, since there is no sharp distinction between digital spying tools and weapons—Stuxnet, for instance, damaged systems as well as stealing secrets—there is a danger that the greater ease of attacking an enemy’s digital assets means that governments will make war on each other with greater abandon. There is a close parallel with drone warfare, which is similarly cheaper and less risky than its flesh-and-blood counterpart. 但网络监控也引发了两个棘手的问题，其一是以这种方式收集信息成本太低廉，这也许会助长它（这种活动）。而且间谍活动螺旋式上升的特性对每个人都不是什么好事。而且，数字监控工具和武器并无明显差别——比如“震网”，除了窃取数据之外还损害系统。还有一个隐患就是攻击敌方的数字机密越容易，双方政府间就越容易发生无所顾忌的战争。这和无人机作战很像，比起血肉横飞的博弈，这反而更便宜且风险更低。 This is an argument for governments to be selective about how they use cyber-weapons not to withdraw them. Although cyber-weapons may lower the threshold for attacks, they don’t (yet) kill or maim people. If the choice is between a missile and a cyber-weapon, the latter is preferable. 关于政府选择如何使用网络武器还是不使用，还存在争论。尽管网络武器也许能降低攻击的门槛，但暂未造成人员伤亡。如果在导弹和网络武器之间选择，后者是更可取的。 #####Working for Main Street, not M The other problem with cyber-weapons is that they encourage economic spying of a sort that has less to do with national security than corporate profits. The West has long complained that the Chinese and Russians help themselves to industrial secrets. But it is not clear that the West’s record is spotless: files leaked by Mr Snowden also suggest that American spies were keenly interested in Petrobras, Brazil’s state-controlled oil firm. 其二是网络武器鼓励了经济间谍活动，它对国家安全影响小但对公司利润则不是。西方长期以来抱怨中国人和俄罗斯人帮他们自己建立机密。但西方他们自己也干净不到哪里去：根据斯诺登先生的泄露出的机密文件显示，美国间谍对Petrobras，一家巴西石油国企很感兴趣。 Here, the question is one of motives. It would be surprising if the West were not spying on Gazprom, for instance, which acts as an arm of the Russian state. But spying on foreign firms to help your own is merely another way of ignoring the intellectual property rules that underlie technological prosperity. Governments should not do it. 在这，这种动机还有一个疑问。举个栗子，如果西方不去监视俄罗斯的左膀右臂——Gazprom，那可能会奇怪。但是监视其他国家来帮自己则完全是另一种行为了，这完全是对知识产权规则的忽视，这（知识产权规则）是科技进步的基石。政府不应这样做。 Cyber-warfare is an unruly business, where rules will be flouted. But it needs them. Cyber-warriors should remember that what they do to others will be done in turn to them. 网络战场没有规矩，在这里规则将被忽视。但是我们需要他们（网络战场）。网络战士们应该记住他们对别人所做的一切都会返还到他们身上。]]></content>
      <categories>
        <category>The Economist(经济学人)</category>
      </categories>
      <tags>
        <tag>Translate Magazines</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The fury of Ferguson]]></title>
    <url>%2F2018%2F04%2F26%2FTE03%2F</url>
    <content type="text"><![CDATA[Race is America’s deepest problem, but multiple small changes can mitigate it RIOTS are rarely so widely anticipated. By 8pm on November 24th, when the prosecutor in Ferguson, Missouri, announced the grand jury’s decision not to charge a police officer with a crime for shooting an unarmed black teenager, Michael Brown, cops in riot gear were already in place and barriers surrounded municipal buildings. Mr Brown’s parents and Barack Obama called for calm. Yet soon America’s TV screens were full of burning police cars, crowds coughing on tear gas, and young black men throwing bricks and smashing shops. America’s history of racial injustice looked as potent as ever. 暴乱是如此的猝不及防。9.24号晚八点，当密苏里州检察官弗格森宣布陪审团的决议：不会起诉警察开枪射击了手无寸铁的男孩迈克-布朗。警察已全副武装围住了市政大楼。布朗的父母和奥巴马呼吁大家冷静。虽然不就美国的电视荧幕上就充满了燃烧的警车，人群在催泪弹中咳嗽，年轻黑人拿着砖头砸商店。美国种族不平等的历史看起来还和以前一样。 [prosecutor] n. 检察官. [municipal ] adj.市政的 [potent] adj. 效力强的 {as …as ever} 和以前一样。 That would be the wrong conclusion to draw. Looking back at the riots in Los Angeles in 1992 that followed the acquittal of four white police officers who had savagely beaten a black motorist, Rodney King, a lot has changed. America has a black president. The LA riots, which left 53 dead, happened in one of America’s great cities, and sparked violence in others. This time the focus was a struggling suburb; in Los Angeles black teenagers protested peacefully alongside white ones. 这种结论将会是错误的，回头看1992年的洛杉矶，4个白人警察暴打一个黑人驾驶员罗德尼·金，但被无罪释放。时过境迁，美国有了黑人总统。洛城暴乱导致53人死亡，这事发生在美国最大的城市之一，影响了其他城市。此次事件焦点在郊区；在洛杉矶的黑人和白人一起进行和平示威活动 [acquittal] n. 宣告无罪。 [ motorist] n. 汽车驾驶员 Blacks plainly still suffer prejudice across America: they account for 86% of the vehicle stops made by police in Ferguson. But America’s race problem is increasingly one of class. Blacks’biggest problem is now poverty, which is most visible in places such as Ferguson. Like many post-war suburbs across America, Ferguson is stuck between the prosperous white exurbs of St Louis and the city’s somewhat revitalized centry. In 1990 its population was three-quarters white; by 2010, it had become two-thirds black. The sub-prime mortgage crisis hit it hard.Many of its homeowners still owe more than they own. 很显然整个国家的黑人遭受歧视：在弗格森，%86的（黑人司机）的车被警察拦下来。但美国的种族问题加深程度远不止此，黑人最大的问题就是贫困，最突出的地方就是诸如密苏里州这样的地方。和整个美国战后的市郊一样，弗格森市被夹在繁荣的圣路易斯白人社区和一些复苏中的中间地带之间。在1990年这里3/4是白人，到了2010年变成了2/3是黑人。次贷危机带来的打击是沉重的，许多房东任然入不敷出。 [revitalised] 卷土重来，恢复 [mortgage] n.抵押(v.); 抵押单据 Solving the problems of places like Ferguson is less about passing more anti-discrimination laws than about rekindling economic growth and spreading the proceeds. But there are also ways of making politics and policing work better that would contribute greatly to racial harmony in America. 解决像弗格森这样的问题不在于通过更多的反歧视法案，而在于复苏其经济，并且增加（居民）收益。也有一些更好的政策和安保工作将会有助于美国民族和睦。 [ rekindle] （现在分词： rekindling）使再燃 [proceed] &gt; 收益 &gt;做另一事 [harmony] (= accord) 和睦; …is less about…than… The police are not an army Ferguson’s political institutions have not kept up with its demography. Of the city’s six-member council, five are white. The hapless mayor, James Knowles, is a white Republican who was re-elected in 2013 in an election in which fewer than one in eight eligible voters turned out.He is in charge of the police force, in which three out of 53 officers are black. Such disparities feed the belief—held by blacks across the country—that both justice and law-enforcement systems are racist. 弗格森的政府部门没有紧跟其人口增长的步伐。6个市政委员中五个是白人。詹姆斯·诺尔斯，这个倒霉的白人市长是个白人共和党人，他在2013年一次不足1/8的有效选举中再次当选（市长）。他控制的警力，53个警察中有三个是黑人。如此的差异让全美黑人认为——不管在司法和执法系统上都是有种族歧视的。 demography 人口统计学的 mayor n.市长. hapless 不幸的 disparities n. 差异 keep up with 紧跟上，紧随步伐 in charge 掌管 Police brutality reinforces that belief. If there was one lesson from the attack on Rodney King,it was that police officers should behave like civilians, not an occupying army. Around 500 people were killed last year by the police—though since nobody counts, nobody really knows. 警察的残暴行为也加剧了这种观念。如果说从袭击罗德尼·金的事件中学到了什么，那就是警察应该像一个平民（ civilians指的是战争中的平民）而不是占领军一样。在去年大约有500人被警察杀死，此后再无人统计过，没有人正真知道这些事情 [behave] 行为；[behave yourself] 自律 [brutality] n. 残暴的行为 if there was…, it was… ,(not …) 如果有…那就是…（而不是…） In Ferguson, bad policies help to explain why distrust turns to anger. Take, for example, the way the town is financed. In 2013 a fifth of Ferguson’s general revenues—some $2.6m, in a cityof 21,000 people—were derived from fines and asset confiscation. That is equivalent to $124 a year for every man, woman and child in the city. Paying fines, even for minor traffic offences,can involve queuing for hours. Those who miss court dates can be jailed until they pay,accumulating more fines along the way. Slowly but surely, the justice system has become an elaborate mechanism for criminalising poverty. *在弗格森市，不良政策能帮助解释为什么不信任演变成愤怒。比如拿当地的财政来说，拥有21000人的弗格森的2.5m的税收的1/5来源于罚款和没收不动产。平均下来人均$124每年，包括市里的男女老少。为了交罚款，即便是微不足道的交通违规，也能导致（市民们）排数小时的队。那些算错日期的人会进监狱直到他们付钱为止，这一路上还会累积更多的罚款。渐渐地，*法律系统变成了一个（为惩罚）criminalising poverty.（就上述行为，不知道怎么翻译[图片上传失败…(image-712101-1516001148054)] ）的复杂的机械。 take away 拿走，夺走 They’re going to take my citizenship away 他们将夺走我的公民权 derive from 来源于; confiscation 没收（常与 confiscation…from…搭配） fine v. n. 罚款 ; minor 不严重的；offence=(offense) 犯罪行为，冒犯行为 [along the way] 一路上 slowly but surely Slowly but surely he started fall in love with her. 渐渐地，他爱上她了。 Smaller cities should stop using their police forces and courts as tax-collectors. Police shootings should be taken much more seriously, and the federal government should stop enabling small police forces to buy military-grade weapons. Proper gun control laws would help: policemen who fear they will be shot are more likely to kill suspects. In their absence, body-mounted cameras might constrain police behaviour. 小城市应该停止将他们的权力和法力作为税收工具的做法。开枪执法应该被认真对待，并且联邦政府应该停止让地方警力去购买军用级别的武器。合适的枪支控制法案将起到作用：警察害怕中枪更有可能射杀嫌疑人。在他们控制不住自己的时候，随身摄像头也许会限制警方的行为。 proper adj.像样的，适宜的 enable to do sth 允许做… be more like to do 更有可能做… Efforts should also be made to increase voter turn out. Ferguson, like many small cities, holds its municipal elections at odd times in odd-numbered years, when little else is on the ballot. If they coincided with national elections, more people would be paying attention. And attempts to restrict voting—by banning Sunday polls, restricting voting hours and requiring people to produce ID—should be resisted. 应该努力增加投票人的参与率。像许多小城市一样，弗格森偶尔会在奇数年举行市政选举，不过是秘密投票。如果碰巧赶上大选，则会有更多人关注。尝试限制投票的做法如——禁止周日投票、限制投票时间还有要求人们出示身份证等这些应该被抵制。 municipal 市政的 Such measures will not inspire great speeches. But the fact that the answers to America’s racial problems now lie in a more vibrant economy and the nitty gritty of politics and policing is itself a form of progress. 这些措施将不会激发大讨论，但是事实美国目前的种族问题取决于更有活力的经济和基础的可行的政策还有治安本身的进步。 vibrant adj.充满活力的 lie in 取决于，秘密是]]></content>
      <categories>
        <category>The Economist(经济学人)</category>
      </categories>
      <tags>
        <tag>Translate Magazines</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018-1-6 The next frontier]]></title>
    <url>%2F2018%2F04%2F26%2FTE02%2F</url>
    <content type="text"><![CDATA[Brain-computer interfaces may change what it means to be human 人机接口也许会改变人的定义。 TECHNOLOGIES are often billed as transformative. For William Kochevar, the term is justified. Mr Kochevar is paralysed below the shoulders after a cycling accident, yet has managed to feed himself by his own hand. This remarkable feat is partly thanks to electrodes, implanted in his right arm, which stimulate muscles. But the real magic lies higher up. Mr Kochevar can control his arm using the power of thought. His intention to move is reflected in neural activity in his motor cortex; these signals are detected by implants in his brain and processed into commands to activate the electrodes in his arms. 科技常被誉为具有革命性。对于威廉·克切沃来说，这个说法很合适。克切沃先生在一场自行车事故后肩部以下瘫痪，虽然他还能够用自己的双手吃饭。这份功劳很大程度上归功于内植入他右臂的刺激肌肉的电极。但真正神奇的地方在更高层处。克切沃先生能用意念控制他的手臂。他移动的意图被反映在他运动皮质层里的神经活动中。这些信号被他大脑内的植入物检测到，经过总部处理来激活手臂里的电极。 paralyze v.使瘫痪 feat n.功绩 electrode n.电极；motor cortex 运动皮质层 be billed as 被誉为 An ability to decode thought in this way may sound like science fiction. But brain-computer interfaces (BCIs) like the BrainGate system used by Mr Kochevar provide evidence that mind-control can work. Researchers are able to tell what words and images people have heard and seen from neural activity alone. Information can also be encoded and used to stimulate the brain. Over 300,000 people have cochlear implants, which help them to hear by converting sound into electrical signals and sending them into the brain. Scientists have “injected” data into monkeys’ heads, instructing them to perform actions via electrical pulses. 以这种方式解码思想听起来像科幻小说。但是脑门系统一样被克切沃先生所使用的脑机接口能证明意念控制是可行的。研究院们能够分辨出人们从神经活动中听到的声音和看到的图片。信息同样能被编码和刺激大脑。超过300000人有耳蜗植入装置，这种装置通过把声音转换成电信号送入电脑以帮助他们的听力。科学家已将数据“注入”猴子的头部，通过电子脉冲控制它们的活动。]]></content>
      <categories>
        <category>The Economist(经济学人)</category>
      </categories>
      <tags>
        <tag>Translate Magazines</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Should digital monopolies be broken up?]]></title>
    <url>%2F2018%2F04%2F26%2Fup%2F</url>
    <content type="text"><![CDATA[###European moves against Google are about protecting companies, not consumers 欧洲反抗Google的运动意在保护其企业，而非消费者 ALTHOUGH no company is mentioned by name, it is very clear which American internet giant the European Parliament has in mind in a resolution that has been doing the rounds in the run-up to a vote on November 27th. One draft calls for “unbundling search engines from other commercial services” to ensure a level playing field for European companies and consumers. This is the latest and most dramatic outbreak of Googlephobia in Europe. 虽然没有任何公司的名字被提及，但很显然的是欧洲委员会已经将哪些美国科技巨头放入11.27号前夕的投票决议中。一项草案呼吁解除搜索引擎与其他商业服务的绑定，以确保对欧洲企业和消费者有一个相对公平的环境。这是最新的，最具戏剧性的欧洲谷歌恐惧症的爆发。 Europe’s former competition commissioner, Joaquín Almunia, brokered a series of settlements this year requiring Google to give more prominence to rivals’ shopping and map services alongside its own in search results. But MEPs want his successor, Margrethe Vestager, to take a firmer line. Hence the calls to dismember the company. 欧洲前竞争委员会委员，Joaqurn Almunia在今年调和了一系列协议，协议要求google给竞争对手的购物和地图方面提供更多的内容，并将其纳入他自己的搜索结果中。不过欧洲议会会员们希望他们的继任Magrethe Vestager 采取更强硬的措施。强烈呼吁解散公司。 The parliament does not actually have the power to carry out this threat. But it touches on a question that has been raised by politicians from Washington to Seoul and brings together all sorts of issues from privacy to industrial policy (see article). How worrying is the dominance of the internet by Google and a handful of other firms? 议会倒是没有什么实际的能力来实施这一威胁，但是他触及了一个已经被从华盛顿到首尔的政客们所提出的问题。被G和其他公司主导的互联网究竟是有多令人担忧？ Who’s afraid of the big bad search engine? Google (whose executive chairman, Eric Schmidt, is a member of the board of The Economist’s parent company) has 68% of the market of web searches in America and more than 90% in many European countries. Like Facebook, Amazon and other tech giants, it benefits from the network effects whereby the popularity of a service attracts more users and thus becomes self-perpetuating. It collects more data than any other company and is better at mining those data for insights. Once people start using Google’s search (and its e-mail, maps and digital storage), they rarely move on. Small advertisers find switching to another platform too burdensome to bother. Google（其执行董事长Eric Schmidit，是经济学人母公司的董事） 在美国有%68的web搜索市场，还有%90的市场在许多欧洲国家。像FB,Amazon和其他的科技巨头一样，通过普及一个业务来吸引更多的用户并因此自我延续。G收集了比其他公司更多的数据，且更擅长挖掘这些数据及洞察力。一旦人们开始使用Google搜索（还有他的邮件，地图和数字存储服务），他们基本不用做什么。小广告商寻找另一个平台则需要做额外的工作以至于他们承受不了。 Google is clearly dominant, then; but whether it abuses that dominance is another matter. It stands accused of favouring its own services in search results, making it hard for advertisers to manage campaigns across several online platforms, and presenting answers on some search pages directly rather than referring users to other websites. But its behaviour is not in the same class as Microsoft’s systematic campaign against the Netscape browser in the late 1990s: there are no e-mails talking about “cutting off” competitors’ “air supply”. What’s more, some of the features that hurt Google’s competitors benefit its consumers. Giving people flight details, dictionary definitions or a map right away saves them time. And while advertisers often pay hefty rates for clicks, users get Google’s service for nothing—rather as plumbers and florists fork out to be listed in Yellow Pages which are given to readers gratis, and nightclubs charge men steep entry prices but let women in free. G显然占据主导地位，但是否其在滥用这个主导地位就是另一回事了。它被指控在搜索结果中偏袒自己的服务。使得广告商在一系列在线平台上的管控活动变得困难。并直接在搜索页面上提前发送搜索结果而不是引导用户去其他网站。但它这个行为并不与90年代后期的微软自动化活动抵制Netscape浏览器那样：没有电子邮件谈切断竞争对手的气源。更多的是一些特点伤害到了G的竞争对手从消费者那里获取利益。给人们提供航班信息，字典释义或地图以快速节约人的时间。虽然广告商支付很高的点击利息，这对消费者什么好处都没有——而不像水管工和花农花钱呗列在黄页上免费提供给读者，还有夜总会要求男士付门票而女士则不必 There are also good reasons why governments should regulate internet monopolies less energetically than offline ones. First, barriers to entry are lower in the digital realm. It has never been easier to launch a new online product or service: consider the rapid rise of Instagram, WhatsApp or Slack. Building a rival infrastructure to a physical incumbent is far more expensive (just ask telecoms operators or energy firms), and as a result there is much less competition (and more need for regulation) in the real world. True, big firms can always buy upstart rivals (as Facebook did with Instagram and WhatsApp, and Google did with Waze, Apture and many more). But such acquisitions then encourage the formation of even more start-ups, creating even more competition for incumbents. 有很多理由解释为什么政府应该花更少了精力规范互联网垄断而非线下。首先，进入数字领域的门槛低。从来没有这么容易推出一个在线的产品或服务：想想看快速兴起的Instagram,WahtsApp或Slack。建设一个可与之匹敌的基础设施到其成型则更加昂贵（只管去问电信运营商或能源公司）。并且它们在现实世界中有更少的竞争者（并需要更多的管控）。讲真，大公司经常能收购新兴竞争对手（就像FB对Ins和WhatsApp所做的那样），但是这种收购反而鼓励了更多出创公司的形成，对现有企业造成更多的竞争。 Second, although switching from Google and other online giants is not costless, their products do not lock customers in as Windows, Microsoft’s operating system, did. And although network effects may persist for a while, they do not confer a lasting advantage: consider the decline of MySpace, or more recently of Orkut, Google’s once-dominant social network in Brazil, both eclipsed by Facebook—itself threatened by a wave of messaging apps. 其次，从google和其他公司里选择的代价比较少，他们的产品并未像Windows那样锁住消费者。尽管其网络影响会持续存在一段时间，但它并没有赋予持久的优势：.…略… Finally, the lesson of recent decades is that technology monopolists (think of IBM in mainframes or Microsoft in PC operating systems) may be dominant for a while, but they are eventually toppled when they fail to move with the times, or when new technologies expand the market in unexpected ways, exposing them to new rivals. Facebook is eating into Google’s advertising revenue. Despite the success of Android, Google’s mobile platform, the rise of smartphones may undermine Google: users now spend more time on apps than on the web, and Google is gradually losing control of Android as other firms build their own mobile ecosystems on top of its open-source underpinnings. So far, no company has remained information technology’s top dog from one cycle to the next. Sometimes former monopolies end up with a lucrative franchise in a legacy area, as Microsoft and IBM have. But the kingdoms they rule turn out to be only part of a much larger map. 最后，近十年的经验教训是技术垄断可能会主导一段时间，但是他们最终会暴露给自己的对手当他们未与时俱进，或是当新技术以意想不到的方式扩大自己的市场 ###Looking after their own 管好你自己 The European Parliament’s Googlephobia looks a mask for two concerns, one worthier than the other. The lamentable one, which American politicians pointed out this week, is a desire to protect European companies. Among the loudest voices lobbying against Google are Axel Springer and Hubert Burda Media, two German media giants. Instead of attacking successful American companies, Europe’s leaders should ask themselves why their continent has not produced a Google or a Facebook. Opening up the EU’s digital services market would do more to create one than protecting local incumbents. 欧洲的谷歌恐惧症就就像一个面具，一面比另一面更有价值。然而美国政客们在本周指出，可悲的一面是其欲保护欧洲企业，在反对G的游说团体中发声最大的是阿克塞尔-施普林格（施普林格出版集团老板）和Hubert Burda（德国媒体巨头）这两个媒体巨头。欧洲领导人应该反思自己为什么他们的大州没有产出像Google和FB一样公司，而不是攻击美国的成功的企业。开放欧洲的数字市场将有主于创造这样（G/FB/Ama）的公司而非保护当地老牌企业。 The good reason for worrying about the internet giants is privacy. It is right to limit the ability of Google and Facebook to use personal data: their services should, for instance, come with default settings guarding privacy, so companies gathering personal information have to ask consumers to opt in. Europe’s politicians have shown more interest in this than American ones. But to address these concerns, they should regulate companies’ behaviour, not their market power. Some clearer thinking by European politicians would benefit the continent’s citizens. 担忧互联网巨头的一个重要原因是隐私。限制G和FB使用私人数据的权限是无可厚非的：如，他们的服务应该默认带有隐私保护，所以公司在使用私人数据时应告知客户寻得许可。欧洲的政客们在这方面表现出比美政客们更多的兴趣，但要表示这些担忧，他们应该规范公司的行为，而不是宏观调控市场。欧洲政客们三思而后行将会有益于欧洲的人民。​]]></content>
      <categories>
        <category>The Economist(经济学人)</category>
      </categories>
      <tags>
        <tag>Translate Magazines</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NewtonMethod]]></title>
    <url>%2F2018%2F04%2F26%2FNewtonMethod%2F</url>
    <content type="text"><![CDATA[#牛顿法和拟牛顿法是是求解最优化问题（函数）的常用方法，具有收敛速度快的特点。 ##牛顿法 考虑无约束最优化问题：其中xxx为目标函数的极小值点 min⁡x∈Rnf(x)\min_{\tiny x \in R^n} {f(x)} x∈Rnmin​f(x) 假设f(x)f(x)f(x)具有二阶连续偏导数，若第k{\tiny k}k次迭代值为xkx_{\tiny k}xk​,则可将f(x)f(x)f(x)在xkx_{\tiny k}xk​附近二阶泰勒展开：二阶泰勒公式可以理解为多项式对目标函数的逼近 f(x)=f(xk)+f′(xk)(x−xk)+f′′(xk)(x−xk)2f(x)=f(x_{\tiny k})+f&#x27;(x_{\tiny k})(x-x_{\tiny k})+\frac {f&#x27;&#x27;(x_{\tiny k})(x-x_{\tiny k})}{2} f(x)=f(xk​)+f′(xk​)(x−xk​)+2f′′(xk​)(x−xk​)​ 这个公式可以理解为等同于目标函数，最优化也就是求解近似解，从极值入手（同上，求解极值点）。那么求极值的必要条件就是一阶导等于0，二阶导不为0，极大极小看方向。 那么设f(x)=0f(x)=0f(x)=0 ; 求近似解的过程：每次迭代从xkx_{\tiny k}xk​开始，下一个极小值点就是xk+1x_{\tiny k+1}xk+1​，再令函数为0。 如图： 为了实现方便，推导一下这个公式： f(xk)+f′(xk)(x−xk)+f′′(xk)(x−xk)2=0f(x_{\tiny k})+f&#x27;(x_{\tiny k})(x-x_{\tiny k})+\frac {f&#x27;&#x27;(x_{\tiny k})(x-x_{\tiny k})}{2}=0f(xk​)+f′(xk​)(x−xk​)+2f′′(xk​)(x−xk​)​=0 x=xk−f′(xk)f′′(xk)x= x_{\tiny k}-\frac{f&#x27;(x_{\tiny k})}{f&#x27;&#x27;(x_{\tiny k})}x=xk​−f′′(xk​)f′(xk​)​ 既有： xk+1=xk−f′(xk)f′′(xk)∗12x_{\tiny k+1}= x_{\tiny k}-\frac{f&#x27;(x_{\tiny k})}{f&#x27;&#x27;(x_{\tiny k})}*{\frac{1}{2}}xk+1​=xk​−f′′(xk​)f′(xk​)​∗21​ 注：以上只讨论了变量个数为1的情形 下面以求平方根的例子理解这个公式： 为构建目标函数，引入： f(x)=x2−cf(x)=x^2-cf(x)=x2−c f′(x)=2xf&#x27;(x)=2xf′(x)=2x 目标变转化为求根问题（变化过程如上图） 一样的泰勒展开，只不过展开到一阶就可以了，二阶没有意义： 彼时的函数为 xk+1=xk−f(xk)f′(xk)x_{\tiny k+1}= x_{\tiny k}-\frac{f(x_{\tiny k})}{f&#x27;(x_{\tiny k})} xk+1​=xk​−f′(xk​)f(xk​)​ 如求解1024: c=1024c=1024c=1024:,假设x0=10x_0=10x0​=10 x1=x0−f(x0)f′(x0)=10−102−10242∗10=56.2x_{\tiny1}= x_{\tiny 0}-\frac{f(x_{\tiny 0})}{f&#x27;(x_{\tiny 0})}= 10-\frac{10^2-1024}{2*10}=56.2x1​=x0​−f′(x0​)f(x0​)​=10−2∗10102−1024​=56.2 x2=x1−f(x1)f′(x1)=56.2−56.22−10242∗56.2=37.2103x_{\tiny2}= x_{\tiny 1}-\frac{f(x_{\tiny 1})}{f&#x27;(x_{\tiny 1})}= 56.2-\frac{56.2^2-1024}{2*56.2}=37.2103x2​=x1​−f′(x1​)f(x1​)​=56.2−2∗56.256.22−1024​=37.2103 $\vdots $ 32.364832.364832.3648 32.002132.002132.0021 323232 每次迭代误差降低： 迭代停止有一个条件可以是XkX_kXk​的变化率趋于0 代码： 12345678910111213141516171819202122const double breaker = 0.0001;const int NewtonMethod(unsigned long long int number)&#123; double Xn; double Xnn = 10.00; do &#123; Xn = Xnn; Xnn= Xn-0.5*((Xn*Xn-number)/Xn); std::cout&lt;&lt;Xnn&lt;&lt;std::endl; &#125;while(std::abs(Xn-Xnn)&gt;breaker); return (int)Xnn;&#125;int main()&#123; unsigned long long int number = 10000000000; //std::cin&gt;&gt;number; //std::cout&lt;&lt;std::sqrt(number)&lt;&lt;std::endl; std::cout&lt;&lt;NewtonMethod(number)&lt;&lt;std::endl;&#125; ##其他 测试标题]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>optimization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模型评估与选择]]></title>
    <url>%2F2018%2F04%2F26%2F%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9%2F</url>
    <content type="text"><![CDATA[模型评估 误差：实际输出与预测输出之间的差值 经验误差：在训练集上的错误率； 泛化误差：在测试集上的错误率 欠拟合与过拟合 欠拟合：模型学习能力低下； 解决办法：增加训练轮数或从模型本身的特征出发：如NN增加神经元个数 过拟合：模型学习能力过于强大 解决办法：无法彻底避免；使经验误差最小化得意缓解 训练、测试数据的划分 留出法: 直接将数据集划分为两个互斥的集合：训练集和测试集 数据划分时应尽量保持数据分布的一致性，各自的正负样本比例应一样; 即便划分后数据分布一样，但是划分方法有很多种，应多用几种划分方式，最后取其模型评估结果的平均值作为最终结果 交叉验证 交叉验证法划分数据集又称“k折交叉验证”，评估结果的稳定性与K关系极大 同样的取划分次数后各自模型的结果平均作为最终结果。 次法结果虽然准确但是开销太大 自助法(bootstrapping): 类似有放回的采样 数据集D样本总数m，每次从D中采样一个样本，重复执行m次获得新数据集 最后大概有%36的数据不会被采样到，这部分数据可作为测试集；这样的测试结果又叫做包外估计（oob，out-of-bag） 当数据集较小或样本分布不均时作用颇大 如何评估泛化性能 回归任务 均方误差（mse） mse=1m∑(f(xi)−yi)2mse =\frac{1}{m}\sum(f(x_i)-y_i)^2mse=m1​∑(f(xi​)−yi​)2 分类任务 错误率：am\frac{a}{m}ma​ 精度：1−am1-\frac{a}{m}1−ma​, 其中，m：样本数，a：分类错误数 分类混淆矩阵： 查准率(精度，precision) precision = TPTP+FP\frac{TP}{TP+FP}TP+FPTP​ 查全率（召回率.recall） recall=TPTP+FNrecall=\frac{TP}{TP+FN}recall=TP+FNTP​ F1 F1=2∗precison∗recallprecision+recallF1 = \frac{2 * precison * recall}{precision+recall}F1=precision+recall2∗precison∗recall​ ROC与AUC 对预测样本的排序能力，评价模型的综合性能 偏差和方差：矛盾体 偏差与方差是矛盾的，偏差高则方差低；反之亦然 偏差：算法本身的学习能力 方差：变换数据所带给它的学习能力的变化]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>model selection AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EM Alrogithm]]></title>
    <url>%2F2018%2F04%2F26%2FEM%2F</url>
    <content type="text"><![CDATA[EM算法描述及应用 场景：某个数据集中有一些数据是缺失的，那么这些数据填充为多少比较合适。这是一个比较有研究意义的问题。 EM很适合解决这个问题： 最大期望算法（Expectation-maximization algorithm，又译期望最大化算法）在统计中被用于寻找，依赖于不可观察的隐性变量的概率模型中（此处理解为缺失值），参数的最大似然估计。 在统计计算中，最大期望（EM）算法是在概率模型中寻找参数最大似然估计或者最大后验估计的算法，其中概率模型依赖于无法观测的隐性变量。最大期望算法经常用在机器学习和计算机视觉的数据聚类（Data Clustering）领域。最大期望算法经过两个步骤交替进行计算，第一步是计算期望（E），利用对隐藏变量的现有估计值，计算其最大似然估计值；第二步是最大化（M），最大化在E步上求得的最大似然值来计算参数的值。M步上找到的参数估计值被用于下一个E步计算中，这个过程不断交替进行。 好难组织语言，代码实现在这里 https://github.com/HCMY/ycimpute/blob/master/ycimpute/unsupervised/expectation_maximization.py]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Adaboost]]></title>
    <url>%2F2018%2F04%2F26%2FAdaboost%2F</url>
    <content type="text"><![CDATA[AdaBoost 属于集成学习算法的一种。集成学习通过构建多个学习任务。结构框架如图所示 集成学习通过多个分类器进行结合，因而大多数情况下拥有较好的泛化性能，以AdaBoost为例，其集成方法各有千秋：可以是同一算法在不同设置下集成；也可以是在不同数据集上集成，一般数据进行抽样训练。 不同的学习器要有一定的准确性，又要有差异性。 如图是Ada的模型： 右边矩形代表不同权重下的数据集（同一数据集） AdaBoost既可以用于分类问题，也可以用于回归问题。 关于如何推导出算法的简洁公式：（二分类为例） 二分类问题 y∈{1,−1}y\in \{1,-1\}y∈{1,−1} 和真实的取值函数f(x)f(x)f(x), 假设基础分类器的错误率为ϵ\epsilonϵ,对于每个分类器hi(x)h_i(x)hi​(x) 有 P[hi(x)≠f(x)]=ϵP[h_i(x)\ne f(x)]=\epsilon P[hi​(x)≠f(x)]=ϵ 原则上若超过半数以上的分类器分类正确，则认为集成分类就是正确的 集成分类器是其线性组合： H(x)=sign(∑t=1Thi(x))H(x)=sign \bigg( \sum_{t=1}^{T}h_i(x)\biggr) H(x)=sign(t=1∑T​hi​(x)) 而在AdaBoost中，有一种加权线性模型： H(x)=∑t=1Tαihi(x)H(x)= \sum_{t=1}^{T}\alpha_i h_i(x) H(x)=t=1∑T​αi​hi​(x) 其中αi\alpha_iαi​为各自分类器的权重。 在分布DDD上，（D为分类器权重向量），定义的最小化损失函数LexpL_{exp}Lexp​的表达式为（exp为 exponential loss function 即最小化损失函数）： Lexp(H∣D)=e−f(x)H(x)L_{exp}(H|D)=e^{-f(x)H(x)} Lexp​(H∣D)=e−f(x)H(x) 一个多元复合函数，要求其最小化，则求偏导；这里需要对目标函数也就是H(x)H(x)H(x)求偏导： H(x)包含取值为1的H_1和取值为-1的H_2,因而链式求偏导过程为： e−f(x)H(x):{f(x):{1,−1H(x):{H1(x)H2(x)e^{-f(x)H(x)}:\begin{cases} f(x):\begin{cases}1,\\-1\end{cases}\\ H(x):\begin{cases}H_1(x)\\H_2(x)\end{cases} \end{cases}e−f(x)H(x):⎩⎪⎪⎪⎪⎨⎪⎪⎪⎪⎧​f(x):{1,−1​H(x):{H1​(x)H2​(x)​​ 那么： \frac{\partial L_{exp}(H|D)}{\partial H(x)}=\frac {\partial e^{-f(x)H(x)}}{\partial H(x)}=\frac {\partial e^{-f_1(x)H_1(x)}}{\partial H_1(x)}+\frac {\partial e^{-f_{-1}(x)H_{-1}(x)}}{\partial H(x)}\\=e^{f_1{(x)H_1(x)}}[-f_1(x)]{\frac {\partial H(x)}{\partial H_1(x)}}+e^{f_{-1}{(x)H_{-1}(x)}}[-f_{-1}(x)]{\frac {\partial H(x)}{\partial H_{-1}(x)}} 因为f1(x)=1f_{1}(x)=1f1​(x)=1与f−1(x)=−1f_{-1}(x)=-1f−1​(x)=−1,代入上式得： ∂Lexp(H∣D)∂H(x)=−e−H1(x)P(f(x)=1∣x)+eH−1(x)P(f(x)=−1∣x)\frac{\partial L_{exp}(H|D)}{\partial H(x)}=-e^{-H_1(x)}P(f(x)=1|x)+e^{H_{-1}(x)}P(f(x)=-1|x)∂H(x)∂Lexp​(H∣D)​=−e−H1​(x)P(f(x)=1∣x)+eH−1​(x)P(f(x)=−1∣x) 令其为0求解： e^{-H_1(x)}P(f(x)=1|x)=e^{H_{-1}(x)}P(f(x)=-1|x) \\ \Rightarrow \frac{e^{H_{-1}(x)}}{e^{-H_{1}(x)}}=\frac{P(f(x)=1|x)}{P(f(x)=-1|x)}=e^{H_1(x)+H_{-1}(x)}=e^{2H(x)} \\两边取对数: \\\Rightarrow H(x)=\frac{1}{2}ln \frac{P(f(x)=1|x)}{P(f(x)=-1|x)} 值得注意的是 H(x)H(x)H(x)一开始由基于算法初始数据分布而来。 因为：Ht(x)=αtf(x)H_t(x)=\alpha_tf(x)Ht​(x)=αt​f(x),那么： \frac{\partial L_{exp}(\alpha_tf(x)|D_t)}{\partial \alpha_t}=\frac{1}{2}ln \frac{1-\epsilon}{\epsilon} \Leftarrow权重更新公式 算法获得Ht−1H_{t-1}Ht−1​后，下一轮学习的hth_tht​将修正Ht−1H_{t-1}Ht−1​的错误： Lexp((Ht−1+ht)∣D)=e−f(x)[Ht−1(x)+ht]=e−f(x)Ht−1(x)∗e−f(x)ht(x)L_{exp}((H_{t-1}+h_t)|D)=e^{-f(x)[H_{t-1}(x)+h_t]}=e^{-f(x)H_{t-1}(x)}*e^{-f(x)h_t(x)} Lexp​((Ht−1​+ht​)∣D)=e−f(x)[Ht−1​(x)+ht​]=e−f(x)Ht−1​(x)∗e−f(x)ht​(x) 对后一项进行二阶泰勒展开： 因为：二阶泰勒展开：ex=1−x+x22e^x=1-x+\frac{x^2}{2}ex=1−x+2x2​ 故上式得：e−f(x)Ht−1(x)∗[1−f(x)ht(x)+f(x)2ht(x)22]e^{-f(x)H_{t-1}(x)}*[1-f(x)h_t(x)+\frac{f_(x)^2h_t(x)^2}{2}]e−f(x)Ht−1​(x)∗[1−f(x)ht​(x)+2f(​x)2ht​(x)2​] 又因为 f(x)2=ht(x)2=1⇒e−f(x)Ht−1(x)∗[1−f(x)ht(x)+12]f_(x)^2=h_t(x)^2=1 \Rightarrow e^{-f(x)H_{t-1}(x)}*[1-f(x)h_t(x)+\frac{1}{2}]f(​x)2=ht​(x)2=1⇒e−f(x)Ht−1​(x)∗[1−f(x)ht​(x)+21​] argmax=e−f(x)Ht−1(x)f(x)ht(x)argmax=e^{-f(x)H_{t-1}(x)}f(x)h_t(x)argmax=e−f(x)Ht−1​(x)f(x)ht​(x) argmax=e−f(x)Ht−1(x)Ex∼D[e−f(x)Ht−1(x)]f(x)ht(x)argmax=\frac{e^{-f(x)H_{t-1}(x)}}{E_x\sim D[e^{-f(x)H_{t-1}(x)}]}f(x)h_t(x)argmax=Ex​∼D[e−f(x)Ht−1​(x)]e−f(x)Ht−1​(x)​f(x)ht​(x) 那么每次权重DDD的迭代： Dt+1=Dt(x)e−f(x)Ht(x)Sum(D(x))=Dt(x)e−αtf(x)ht(x)Sum(D(x))D_{t+1}=\frac{D_t(x)e^{-f(x)H_{t}(x)}}{Sum(D(x))}=\frac{D_t(x)e^{-\alpha_tf(x)h_{t}(x)}}{Sum(D(x))} Dt+1​=Sum(D(x))Dt​(x)e−f(x)Ht​(x)​=Sum(D(x))Dt​(x)e−αt​f(x)ht​(x)​ 下面是代码，公式所有代码实现均在train方法里面：注意一点就是：第一个分类器是基于算法初始数据分布而来（和猜差不多？），此后迭代的生成hth_tht​和αt\alpha_tαt​，而后生成DtD_tDt​ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980class AdaBoost(object): def __init__(self,data_matrix,labels,iter_nums): self.X = np.matrix(data_matrix) self.y = np.matrix(labels) samples = np.shape(data_matrix)[0] self.D = np.mat(np.ones((samples,1))/samples) self.iter = range(iter_nums) def stumpClassfily(self,data_matrix,dimen,thresh_val,thresh_ineq): rest_arr = np.ones((np.shape(data_matrix)[0],1)) if thresh_ineq is 'lt': rest_arr[data_matrix[:,dimen]&lt;=thresh_val] = -1.0 else: rest_arr[data_matrix[:,dimen]&gt;thresh_val] = -1.0 return rest_arr def buildStump(self): samples,features = np.shape(self.X) num_steps = 10 best_stump = &#123;&#125; best_class_estimate = np.mat(np.zeros((samples,1))) min_error = np.inf for i in range(features): range_min = self.X[:,i].min() range_max = self.X[:,i].max() step_size = (range_max-range_min)/num_steps for j in range(-1,num_steps+1): for inequal in ['lt','gt']: thresh_val = (range_min+float(j)*step_size) predict_val = self.stumpClassfily(self.X,i,thresh_val,inequal) error_matrix = np.matrix(np.ones((samples,1))) error_matrix[predict_val==self.y.T] = 0 weight_error = self.D.T * error_matrix if weight_error &lt; min_error: min_error = weight_error best_class_estimate = predict_val.copy() best_stump['dim'] = i best_stump['thresh'] = thresh_val best_stump['ineq'] = inequal return best_stump,min_error,best_class_estimate def train(self): weak_class_arr = [] samples = np.shape(self.X)[0] aggravete_class_est = np.mat(np.zeros((samples,1))) for rounds in self.iter: best_stump,error,class_est = self.buildStump() alpha = float(0.5*np.log((1.0-error)/max(error,1e-16))) best_stump['alpha'] = alpha weak_class_arr.append(best_stump) expon_loss_func = np.multiply(-1*alpha*self.y.T,class_est) self.D = np.multiply(self.D,np.exp(expon_loss_func)) self.D = self.D/self.D.sum() aggravete_class_est += alpha*class_est agg_errors_matrix = np.multiply(np.sign(aggravete_class_est)!=self.y.T, np.ones((samples,1))) error_rate = agg_errors_matrix.sum()/samples if error_rate is 0.0:break return weak_class_arr class Predcitor(AdaBoost): def __init__(self,data_matrix,classifyer_set): self.X = data_matrix self.classifyers = classifyer_set def predict(self): samples = np.shape(self.X)[0] agg_class_est = np.mat(np.zeros((samples,1))) for classifyer in self.classifyers: class_est = self.stumpClassfily(self.X,classifyer['dim'], classifyer['thresh'], classifyer['ineq']) agg_class_est += classifyer['alpha']*class_est return np.sign(agg_class_est)]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DecisionTree]]></title>
    <url>%2F2018%2F04%2F26%2FDecisionTree%2F</url>
    <content type="text"><![CDATA[决策树是一个有监督的分类模型。以二分类为例，从复杂的离散型数据中学习一种模式。 这里使用西瓜书的数据集 编号,色泽,根蒂,敲声,纹理,脐部,触感,密度,含糖率,好瓜 1,青绿,蜷缩,浊响,清晰,凹陷,硬滑,0.697,0.46,是 2,乌黑,蜷缩,沉闷,清晰,凹陷,硬滑,0.774,0.376,是 3,乌黑,蜷缩,浊响,清晰,凹陷,硬滑,0.634,0.264,是 4,青绿,蜷缩,沉闷,清晰,凹陷,硬滑,0.608,0.318,是 5,浅白,蜷缩,浊响,清晰,凹陷,硬滑,0.556,0.215,是 6,青绿,稍蜷,浊响,清晰,稍凹,软粘,0.403,0.237,是 7,乌黑,稍蜷,浊响,稍糊,稍凹,软粘,0.481,0.149,是 8,乌黑,稍蜷,浊响,清晰,稍凹,硬滑,0.437,0.211,是 9,乌黑,稍蜷,沉闷,稍糊,稍凹,硬滑,0.666,0.091,否 10,青绿,硬挺,清脆,清晰,平坦,软粘,0.243,0.267,否 11,浅白,硬挺,清脆,模糊,平坦,硬滑,0.245,0.057,否 12,浅白,蜷缩,浊响,模糊,平坦,软粘,0.343,0.099,否 13,青绿,稍蜷,浊响,稍糊,凹陷,硬滑,0.639,0.161,否 14,浅白,稍蜷,沉闷,稍糊,凹陷,硬滑,0.657,0.198,否 15,乌黑,稍蜷,浊响,清晰,稍凹,软粘,0.36,0.37,否 16,浅白,蜷缩,浊响,模糊,平坦,硬滑,0.593,0.042,否 17,青绿,蜷缩,沉闷,稍糊,稍凹,硬滑,0.719,0.103,否 信息熵： 数据集D的信息熵为：$$Ent(D)=-\sum_{k=1}^{y}P_k*log_2P_k$$ 以数据为例： 对于标签列，是否为好瓜的这一“属性”的信息熵就是： y的取值只有两个，是(1)和否(0)。那么P1=817P_1=\frac{8}{17}P1​=178​, P0=917P_0=\frac{9}{17}P0​=179​ 然而为了计算信息增益，有些特征会有很多取值，同一个特征不各个值都需要计算熵，如敲声： 根蒂取值各为：浊响(D1) ,沉闷(D2)，清脆(D3) 三个 D1的信息熵为: 当前数据特征‘敲声’下，取值为‘浊响’，被化为正类的：P1=610P_1=\frac{6}{10}P1​=106​, P0=410P_0=\frac{4}{10}P0​=104​ 其信息熵为：0.9709 123456789101112131415161718192021#input: one parameter#data type: pandas DataFrame; content: [fea1,fea2,...,fea,lable]#out put: entropydef calcutaleEnt(self,data_set): num_samples = len(data_set) lable_list = set(list(data_set[self.lable])) count_dic = data_set.groupby(by=self.lable).count().to_dict() main_key_list = list(count_dic.keys()) cal_dic = &#123;&#125; for item in lable_list: count_dic[item] = 0 for main_key in main_key_list: for lable in lable_list: cal_dic[lable] = count_dic[main_key][lable] ent = 0.0 for key in cal_dic.keys(): prob = float(cal_dic[key])/num_samples ent-=prob*math.log(prob,2) return ent 树有不同的分支节点，不同分支节点，即同一个特征下的特征取值，所包含的样本数目不同，为了让样本数越多的分支节点权重越大，引入信息增益以刻画每个特征，为了更好的分类。 信息增益 Gain(D,a)=Ent(D)−∑v=1V∣Dv∣∣D∣∗Ent(Dv)Gain(D,a)=Ent(D)-\sum_{v=1}^{V}\frac{\rvert D^v \rvert}{\rvert D\rvert}*Ent(D^v) Gain(D,a)=Ent(D)−v=1∑V​∣D∣∣Dv∣​∗Ent(Dv) 其中，Ent(D)Ent(D)Ent(D)为原始信息熵，即全数据（标签列）；在刚刚的类别下，DvD^vDv= 浊响(D1) ,沉闷(D2)，清脆(D3) 计算完每个特征的信息增益后，就可以从已有特征中选出最好的特征，即信息增益最大的特征 1234567891011121314151617181920212223def inforGain(self,data_set): base_ent = self.calcutaleEnt(data_set) best_feature = '' base_inforgain = 0.0 feature_list = list(data_set.columns) feature_list.remove(self.lable) for feature in feature_list: this_feature_samples = self.getFeatureProprity(data_set[feature]) fea_val_list = set(list(data_set[feature])) feature_ent = 0.0 for fea_val in fea_val_list: extract_data = self.splitData(data_set,feature,fea_val) cell_fea_sample = self.getFeatureProprity(extract_data) cell_feature_ent = (abs(cell_fea_sample)/abs(this_feature_samples))*self.calcutaleEnt(extract_data) feature_ent += cell_feature_ent tmp_infor_gain = base_ent-feature_ent print ("feature=",feature,"inforGain=",tmp_infor_gain) if tmp_infor_gain &gt; base_inforgain: base_inforgain = tmp_infor_gain best_feature = feature return best_feature 1234567def splitData(self,data_set,feature,value): columns = list(data_set.columns) columns.remove(feature) restData = data_set[data_set[feature]==value] restData = restData[columns] return restData 最后建立树，并预测。 12345678910def predicter(self,tree,features,testX): first_key = list(tree.keys())[0] second_dict = tree[first_key] for key in second_dict.keys(): if testX[first_key][0] == key: if type(second_dict[key]).__name__ == 'dict': class_lable = self.predicter(second_dict[key],features,testX) else: class_lable = second_dict[key] return class_lable]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intellegience</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LogisticRegression]]></title>
    <url>%2F2018%2F04%2F26%2FLogisticRegression%2F</url>
    <content type="text"><![CDATA[在给定X的条件下，其被分到 1 类 的概率为： P(Y=1∣x,Q)=Sigmoid(a+x∗Q)P(Y=1\mid x,Q)=Sigmoid(a+x*Q)P(Y=1∣x,Q)=Sigmoid(a+x∗Q)(a为偏置，和线性方程a+bx是一个道理) 其中Sigmoid(QX)Sigmoid(QX)Sigmoid(QX)的计算方式是: P(Y=1∣x,Q)=e(a+x∗Q)1+e(a+x∗Q)P(Y=1\mid x,Q)=\frac{e^(a+x*Q)}{1+e^(a+x*Q)}\qquadP(Y=1∣x,Q)=1+e(a+x∗Q)e(a+x∗Q)​ 这样计算有些复杂，化简后为： P(Y=1∣x,Q)=11+e−(x∗Q)P(Y=1\mid x,Q) = \frac{1}{1+e^-(x*Q)}P(Y=1∣x,Q)=1+e−(x∗Q)1​ Q为权值向量，x为输入样本，比如有5个特征，则Q向量为 [x1 x2 x3 x4 x5]⊤\begin{bmatrix} x_1\ x_2\ x_3\ x_4 \ x_5 \end{bmatrix}^\top[x1​ x2​ x3​ x4​ x5​​]⊤ x∗Qx*Qx∗Q 后所生成的向量代入Sigmoid()Sigmoid()Sigmoid() 后就可以得出类别 这是一个概率值，因为Q值是固定的。我们直接输入x矩阵值就好了，算法会告诉我们 Y 值能取到多少，也就是概率值为多少 ，然后大于y&gt;0.5为1类，y&lt;0.5为0类； 12def sigmoid(self,x): return 1.0/(1+np.exp(-x)) 相应的其被分到 0 类的概率为： P(Y=0∣x,Q)=1−P(Y=1∣x,Q)P(Y=0\mid x,Q)=1-P(Y=1\mid x,Q)P(Y=0∣x,Q)=1−P(Y=1∣x,Q) 但Q值怎么算和为什么这个算法可以这么算？我的理解是这样的，多元回归函数可以表示为： $Y_{1} =a + b_{x_{1} }+cx_{2}+dx_{3}…+mx_{n} $ 其实他就是一个概率的问题，可以这么理解：回归预测后得出的值是控制了自变量后得出的概率 ；也就是说预测值Y越高，自变量可能更具有某种特性，从而影响了Y值；线性回归假设了概率与X值呈现出一条直线。（就像你每增长一岁，你被催婚的概率会增大） 但 这个多元函数所带来的一个麻烦就是：概率最大值为1，最小值为0；如果单纯看这个函数的话，Y值总有一刻会&gt;1或&lt;0，这和我们的思维很不和谐，解决这样的问题的一个最好的办法就是：任何&gt;1的值都用1替代，任何&lt;0的值都用0替代；这样就会出现任何&gt;1的值和&lt;0的值都将呈现出一条直线： 这样的做法的确解决了概率大小超出范围的问题，但是它显得太绝对了一点，它把一切&gt;1和&lt;0的值都瞬间变为一条直线，也就是表达了当自变量达到一定值得时候对因变量就没有影响了，这样显然太绝对了，举一个例子： “Y就像你买一套房子的期望，x1是你的工资，x2是你所在的城市，x3是房子的地段 假如你的工资上涨，或房子地段相对不好，那么你买房子的概率就会上升，反之亦然；当你工资 多到一定程度 的时候，工资即使再涨，对你买房子的概率也不会有很大很大的影响，因为你已经有很多钱了，再往上加工资没有太大意义,但没人会和钱过不去，钱当然是越多越好，你可以买更好的房子或你可以更快买到房子；同样的，当你工资少的可怜的时候，即时再给他降低工资也不会对他产生很大很大的影响，因为他不可能买到房。 而对于中间一部分人来说，加/减 工资 或地段等其他因素带来的影响会很大，但加了工资换了地段你就会买房子么？不一定，因为你还没满足条件，只是说你买房子的概率会上升“ 避免这样太过绝对的方法就是当自变量大到一定程度的时候，对因变量的影响相对于中间部分的影响变得很小，刚好有这样的曲线可以很好的达到我们想要的效果： S形曲线：无限趋于上下限，也就是Logit模型,也就是sigmoid： 但回归不是一条直线么？怎么会变成曲线？可以看下这幅图： 把切线上的斜率取均值，得到一条趋势线，用直线模拟曲线。 但我们很容易发现对于这种线性关系，因变量和自变量的关系在极限段是被高估了的，而在中间段是被低估了的，因变量对自变量的影响是不对的，要么过大，要么过小；我们想要以S形状曲线预测，但是从回归可以看出每一个自变量本身都会对因变量产生影响，但当某个自变量大到足以让Y很接近1的时候，其他自变量就没法工作了，他们就不可以相互作用了，也违背了回归的原则，这样的话直接拿一个因变量检测好了，干嘛还要那么多自变量？解决这个矛盾的方法就是排除上下限，也就是需要把Logit函数做一些转化； ###排除上限： 设 x 被 分为 1 类 的概率是：PiP_iPi​ ，则被分为0 的概率就是：1−Pi1-P_i1−Pi​ 然后取他们的比作为Y值的概率：Pi1−Pi\frac{P_{i} }{1-P_{i} }1−Pi​Pi​​ 因为与概率不同的是比没有上限，但下限为0； 当概率值PiP_{i}Pi​ 无限趋于1的时候，其比也就是：Logit=Pi1−PiLogit=\frac{P_{i} }{1-P_{i} }Logit=1−Pi​Pi​​ 被无限放大，上限也就不存在了； 而且比数还有一个作用就是：倍数关系，分子是分母的多少倍，也就是说取到1的概率是取到0的几倍； ###排除下限： 为了排除下限，我们就需要当自变量$\frac{P_{i} }{1-P_{i} } 趋于0时，Logit函数趋于负无穷； 刚好：取对数可以做到这一点，有能保证自变量>0： 也就是：Logit=ln\left( \frac{P_{i} }{1-P_{i} } \right)$ 到这里为止 上下限被排除，转化也就结束了 然后把S形曲线线性化： Logit=ln(Pi1−Pi)=a+xi∗QLogit=ln\left( \frac{P_{i} }{1-P_{i} } \right) =a+x_{i}*QLogit=ln(1−Pi​Pi​​)=a+xi​∗Q 为了更加表达清楚他们是概率的关系：两边取指数 eln(Pi1−Pi)=ea+xi∗Qe^{ln\left( \frac{P_{i} }{1-P_{i} } \right) } =e^{a+x_{i}*Q }eln(1−Pi​Pi​​)=ea+xi​∗Q 化简后就是： Pi1−Pi=ea+xi∗Q\frac{P_{i} }{1-P_{i} } =e^{a+x_{i}*Q }1−Pi​Pi​​=ea+xi​∗Q Pi=ea+xi∗QP_{i}=e^{a+x_{i}*Q }Pi​=ea+xi​∗Q $P_{i}*e^{x_{i}*Q} $ 1=ea+xi∗QPi−ea+xi∗Q1=\frac{e^{a+x_{i} *Q} }{P_{i} } -e^{a+x_{i}*Q }1=Pi​ea+xi​∗Q​−ea+xi​∗Q $P_{i}=\frac{e^{a+x_{i}*Q } }{1+e^{a+x_{i}*Q} } $ 按理来说，Y被取到1 的概率应该就是这样的，接下来该是做的就是看如何把Q值算出来，对于模型的参数（Q）估计，这里使用极大似然函数 我们用Li(Q)Li(Q)Li(Q)表示： $Li\left( Q \right) =\prod_{i=1}^{n} \left{ P(y=1\mid x_{i} )^{y_{i} } \ast P(Y=0\mid x_{i} )^{1-y_{i} } \right} $ Li(Q)=∏i=1n{(ea+xi∗Q1+ea+xi∗Q)yi∗(11+ea+xiQ)1−yi}Li(Q)=\prod_{i=1}^{n} \left\{ (\frac{e^{a+x_{i}*Q } }{1+e^{a+x_{i}*Q } } )^{y_{i} }\ast (\frac{1}{1+e^{a+x_{i}Q } } )^{1-y_{i} } \right\}Li(Q)=∏i=1n​{(1+ea+xi​∗Qea+xi​∗Q​)yi​∗(1+ea+xi​Q1​)1−yi​} 取对数后化成加法: Li(Q)={∑i=1nyi∗ln(ea+xi∗Qa+ea+xi∗Q)+∑i=1n(1−yi)∗ln(11+ea+xi∗Q)}Li(Q)=\left\{ \sum_{i=1}^{n}{y_{i} \ast ln(\frac{e^{a+x_{i}*Q } }{a+e^{a+x_i*Q } } )}+\sum_{i=1}^{n}{(1-y_{i} )*ln(\frac{1}{1+e^{a+x_i*Q } } )} \right\}Li(Q)={∑i=1n​yi​∗ln(a+ea+xi​∗Qea+xi​∗Q​)+∑i=1n​(1−yi​)∗ln(1+ea+xi​∗Q1​)} Li(Q)=∑i=1nyi∗ln(ea+xi∗Q1+ea+xi∗Q)+∑i=1nln(11+ea+xi∗Q)−∑i=1nyi∗ln(11+ea+xi∗Q)Li(Q)=\sum_{i=1}^{n}{y_{i}*ln(\frac{e^{a+x_{i}*Q } }{1+e^{a+x_{i} *Q} } )+\sum_{i=1}^{n}{ln(\frac{1}{1+e^{a+x_{i}*Q } } )} -\sum_{i=1}^{n}{y_{i}*ln(\frac{1}{1+e^{a+x_{i}* Q} } )} }Li(Q)=∑i=1n​yi​∗ln(1+ea+xi​∗Qea+xi​∗Q​)+∑i=1n​ln(1+ea+xi​∗Q1​)−∑i=1n​yi​∗ln(1+ea+xi​∗Q1​) $Li(Q)=\sum_{i=1}{n}{y_{i}*ln(\frac{\frac{e{a+x_{i}*Q } }{1+e^{a+x_{i}*Q } } }{\frac{1}{1+e^{a+x_{i}*Q } } } )-\sum_{i=1}{n}{ln(\frac{1}{1+e{a+x_{i}*Q } } )} } $ $Li(Q)=y_{i}*(a+x_{i}*Q )-\sum_{i=1}{n}{ln(1+e{a+x_{i}*Q } )} $ 整个模型的代价函数化到这里就没办法再化下去了： 根据多元函数求极值法：对代价函数求偏导后得： $\frac{\partial Li(Q)}{\partial Q} =\sum_{I=1}^{N}{y_{i} *x_{i} -\sum_{i=1}{n}{\frac{1}{1+e{a+x_{i}*Q } } }*e^{a+x_{i}*Q } *x_{i} } $ 然后令其为0：一看就解不出Q，这样的话要求解只能用梯度上升/下降求最优解了：这里希望Y值尽可能取到1的概率增加，所以用梯度上升（不知道说的对不对，没有对的话还请指教，感激！） 先初始化一个权值矩阵Q，在进行迭代： $Q^{t+1} =Q^{t} +\alpha *\sum_{i=1}^{n}{x_{i} *(y_{i}-\frac{e^{a+x_{i}*Q ^t } }{1+e{a+x_{i}*Q{t} } } )} $ 这里我们也看到了Sigmoid函数，经过反复迭代后得到一个局部最优解，可是如何防止跳过局部最优解还得慢慢试，不知道有没有其他的模型能帮忙解决这个问题。 迭代完后保存权值矩阵，a值可以设为1； 之后把权值矩阵做一个处理就可以看到效果，或者直接把预测结果写入文件在来一次K折交叉看看模型的准确率。 最后附代码片段 123456789101112131415161718192021class LogisticRegressionClassifier(object): def __init__(self,alpha,n_iter): self.alpha = alpha self.iter = n_iter def sigmoid(self,x): return 1.0/(1+np.exp(-x)) def train(self,X,y): samples,features = np.shape(X) weights = np.ones((features,1)) error = np.ones((features,1)) for times in range(self.iter): output = self.sigmoid(X*weights) error = y-output weights = weights+self.alpha*X.transpose()*error return weights def predict(self,X,weights): results = self.sigmoid(X*weights) return results]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Aitficial Intellegiences</tag>
      </tags>
  </entry>
</search>
